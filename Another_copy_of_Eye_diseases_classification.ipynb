{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepthi-neelam/deepthi/blob/main/Another_copy_of_Eye_diseases_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPxvzm0qqIMo"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSHFk94K-XGc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'eye-diseases-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2440665%2F4130910%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240801%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240801T114054Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7c5dd42f88acbdca7c3ae691aac8ef99ad9b95d1dad4c005e8a4d8a6e262b66608dc52432173d09ffac9a5ce44d2ca9f8552d0fdd807cc4036cc9b232fa7efa3de7cd3deb48dfc430d6873b88f919272ffb1747bd5b391db412d8189c9adb4cd7cd5511f05b54c817d738da8a7f78f98c78539b786369c769432d8b8a2bdc7615da4182d5f8817b57af2c07d7081805828486130f10778fa7f88c60fc088aacc56838fb9f2f2db138bda8197a6b333b66b342a9062437b2d22df56cf1146d8f10ac47e5860114cb08fe5ca2014828d27fbf559b3a758bd334bef365ff5879dd5a8f5c359a77c893652f7bcbe030b9b394aec9c7ee9cdee4f3b04aa942f4fae5d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B3hJ4E0qexf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNa48xeg-XGx"
      },
      "source": [
        "## Eye diseases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9RFzI-T-XG3"
      },
      "source": [
        "Diabetes is a condition that carries an increased risk of developing eye complications. Diabetic eye disease includes complications such as diabetic retinopathy, cataracts and glaucoma.\n",
        "\n",
        "Diabetes is the leading cause of blindness in working-age adults. People with type 1 and type 2 diabetes are at risk. It’s possible to be unaware that you have severe diabetic eye disease and suddenly go blind. Fortunately, most cases of blindness can be prevented with regular eye examinations and proper care.\n",
        "\n",
        "- The dataset consists of Normal, Diabetic Retinopathy, Cataract and Glaucoma retinal images where each class have approximately 1000 images. These images are collected from various sorces like IDRiD, Oculur recognition, HRF etc.\n",
        "\n",
        "- Diabetic retinopathy: The persistently high blood sugar levels that occur with diabetes can damage the retina’s small blood vessels (capillaries), which deliver oxygen and nutrients. Diabetic retinopathy affects up to a third of people with diabetes over the age of 502.\n",
        "\n",
        "- Cataracts: A cataract is a clouding of the lens in the eye. Left untreated, cataracts can eventually lead to blindness. People with diabetes are more likely to develop cataracts at an earlier age and suffer visual impairment faster than those without the condition.1,3\n",
        "\n",
        "- Glaucoma: This is a group of conditions that can damage the optic nerve. The optic nerve transmits signals from the retina to the brain for processing. Glaucoma is often (but not always) a result of increased pressure inside the eye. The risk of glaucoma in people with diabetes is significantly higher than that of the general population.1,4 The two main types are open-angle glaucoma (also called ‘the sneak thief of sight’) and angle-closure glaucoma (this comes on suddenly and is a medical emergency)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kzKopl3-XG6"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7d1LBepwX1b"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql3GNB_l-XG8"
      },
      "outputs": [],
      "source": [
        "# import system libs\n",
        "import os\n",
        "import time\n",
        "# import data handling tools\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation, GlobalAveragePooling2D\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DutLAC0C-XG-"
      },
      "source": [
        "## Class for Loading and Splitting Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyVXbQ-Y-XHA"
      },
      "outputs": [],
      "source": [
        "class EyeDiseaseDataset:\n",
        "    def __init__(self, dataDir):\n",
        "        self.data_dir = dataDir\n",
        "\n",
        "    def dataPaths(self):\n",
        "        filepaths = []\n",
        "        labels = []\n",
        "        folds = os.listdir(self.data_dir)\n",
        "        for fold in folds:\n",
        "            foldPath = os.path.join(self.data_dir, fold)\n",
        "            filelist = os.listdir(foldPath)\n",
        "            for file in filelist:\n",
        "                fpath = os.path.join(foldPath, file)\n",
        "                filepaths.append(fpath)\n",
        "                labels.append(fold)\n",
        "        return filepaths, labels\n",
        "\n",
        "    def dataFrame(self, files, labels):\n",
        "\n",
        "        Fseries = pd.Series(files, name='filepaths')\n",
        "        Lseries = pd.Series(labels, name='labels')\n",
        "        return pd.concat([Fseries, Lseries], axis=1)\n",
        "\n",
        "    def split_(self):\n",
        "        files, labels = self.dataPaths()\n",
        "        df = self.dataFrame(files, labels)\n",
        "        strat = df['labels']\n",
        "        trainData, dummyData = train_test_split(df, train_size=0.8, shuffle=True, random_state=42, stratify=strat)\n",
        "        strat = dummyData['labels']\n",
        "        validData, testData = train_test_split(dummyData, train_size=0.5, shuffle=True, random_state=42, stratify=strat)\n",
        "        return trainData, validData, testData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYh0R9LN-XHC"
      },
      "outputs": [],
      "source": [
        "dataDir='/kaggle/input/eye-diseases-classification/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8ooP5Xc-XHE"
      },
      "outputs": [],
      "source": [
        "dataSplit = EyeDiseaseDataset(dataDir)\n",
        "train_data, valid_data, test_data = dataSplit.split_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq9HIyO0-XHG"
      },
      "outputs": [],
      "source": [
        "def display_random_image(df):\n",
        "    random_row = df.sample(1).iloc[0]\n",
        "    filepath = random_row['filepaths']\n",
        "    label = random_row['labels']\n",
        "\n",
        "    img = Image.open(filepath)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Label:{label}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_random_image(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pnHzLYJ-XHH"
      },
      "source": [
        "## Function for Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5Cq74hh-XHI"
      },
      "outputs": [],
      "source": [
        "def augment_data( train_df, valid_df, test_df, batch_size=16):\n",
        "\n",
        "    img_size = (256,256)\n",
        "    channels = 3\n",
        "    color = 'rgb'\n",
        "\n",
        "\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "              rotation_range=30,\n",
        "              horizontal_flip=True,\n",
        "              vertical_flip=True,\n",
        "              brightness_range=[0.5, 1.5])\n",
        "\n",
        "    valid_test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "              train_df,\n",
        "              x_col='filepaths',\n",
        "              y_col='labels',\n",
        "              target_size=img_size,\n",
        "              color_mode=color,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=True,\n",
        "              class_mode='categorical'\n",
        "          )\n",
        "\n",
        "    print(\"Shape of augmented training images:\", train_generator.image_shape)\n",
        "\n",
        "    valid_generator = valid_test_datagen.flow_from_dataframe(\n",
        "              valid_df,\n",
        "              x_col='filepaths',\n",
        "              y_col='labels',\n",
        "              target_size=img_size,\n",
        "              color_mode=color,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=True,\n",
        "              class_mode='categorical'\n",
        "          )\n",
        "\n",
        "    print(\"Shape of validation images:\", valid_generator.image_shape)\n",
        "\n",
        "    test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "              test_df,\n",
        "              x_col='filepaths',\n",
        "              y_col='labels',\n",
        "              target_size=img_size,\n",
        "              color_mode=color,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=False,\n",
        "              class_mode='categorical'\n",
        "          )\n",
        "\n",
        "    print(\"Shape of test images:\", test_generator.image_shape)\n",
        "\n",
        "    return train_generator, valid_generator, test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3EVqdLF-XHJ"
      },
      "outputs": [],
      "source": [
        "train_augmented, valid_augmented, test_augmented = augment_data(train_data, valid_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp3LkKNH-XHK"
      },
      "outputs": [],
      "source": [
        "def show_images(gen):\n",
        "\n",
        "    g_dict = gen.class_indices        # defines dictionary {'class': index}\n",
        "    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n",
        "    images, labels = next(gen)        # get a batch size samples from the generator\n",
        "    length = len(labels)\n",
        "    sample = min(length, 20)\n",
        "    plt.figure(figsize= (15, 17))\n",
        "    for i in range(sample):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        image = images[i] / 255\n",
        "        plt.imshow(image)\n",
        "        index = np.argmax(labels[i])\n",
        "        class_name = classes[index]\n",
        "        plt.title(class_name, color= 'blue', fontsize= 7 )\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "show_images(train_augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXRxHONZ-XHL"
      },
      "source": [
        "## Download and compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW2Xojip-XHM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "classes = len(list(train_augmented.class_indices.keys()))\n",
        "\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu' , kernel_regularizer = regularizers.l2(0.01))(x)\n",
        "\n",
        "predictions = Dense(classes, activation='softmax', kernel_regularizer = regularizers.l2(0.01))(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tHa8G83-XHN",
        "outputId": "dc3037bd-d570-4e50-e4c0-46202f6f06a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 545ms/step - accuracy: 0.6778 - loss: 4.2753 - val_accuracy: 0.6943 - val_loss: 1.0360\n",
            "Epoch 2/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 367ms/step - accuracy: 0.7613 - loss: 0.9021 - val_accuracy: 0.7204 - val_loss: 0.8993\n",
            "Epoch 3/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 357ms/step - accuracy: 0.7616 - loss: 0.7916 - val_accuracy: 0.7559 - val_loss: 0.7854\n",
            "Epoch 4/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 361ms/step - accuracy: 0.7608 - loss: 0.7543 - val_accuracy: 0.7464 - val_loss: 0.7586\n",
            "Epoch 5/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 356ms/step - accuracy: 0.7770 - loss: 0.6992 - val_accuracy: 0.7583 - val_loss: 0.7731\n",
            "Epoch 6/15\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 357ms/step - accuracy: 0.7479 - loss: 0.7420 - val_accuracy: 0.7844 - val_loss: 0.6958\n",
            "Epoch 7/15\n",
            "\u001b[1m 66/211\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 355ms/step - accuracy: 0.7839 - loss: 0.6877"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_augmented,\n",
        "    epoc uphs=15,\n",
        "    validation_data=valid_augmented,\n",
        "\n",
        "\n",
        "    );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft8DwToB-XHM"
      },
      "source": [
        "## Fit the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Oz0Sbb-XHO"
      },
      "source": [
        "## Plot the Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxjAgGzo-XHO"
      },
      "outputs": [],
      "source": [
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "print(\"Training Accuracy:\", train_accuracy[-1])\n",
        "print(\"Validation Accuracy:\", val_accuracy[-1])\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVAD1Ios-XHP"
      },
      "source": [
        "## Display the Actual and Predicted images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N11wqjOKGfeg"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Uerdzeg-XHP"
      },
      "outputs": [],
      "source": [
        "def plot_actual_vs_predicted(model, test_data, num_samples=7):\n",
        "\n",
        "    # Get a batch of test data\n",
        "    test_images, test_labels = next(iter(test_data))\n",
        "\n",
        "    predictions = model.predict(test_images)\n",
        "\n",
        "    class_labels = list(train_augmented.class_indices.keys())\n",
        "\n",
        "    sample_indices = np.random.choice(range(len(test_images)), num_samples, replace=False)\n",
        "      # Plot the images with actual and predicted labels\n",
        "    for i in sample_indices:\n",
        "        actual_label = class_labels[np.argmax(test_labels[i])]\n",
        "        predicted_label = class_labels[np.argmax(predictions[i])]\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        # Actual Image\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(test_images[i].astype(np.uint8))\n",
        "        plt.title(f'Actual: {actual_label}')\n",
        "        plt.axis('off')\n",
        "        # Predicted Image\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(test_images[i].astype(np.uint8))\n",
        "        plt.title(f'Predicted: {predicted_label}')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "plot_actual_vs_predicted(model, test_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQGwAXk__Wcf"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save('eye.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKmD30Y8QNw_"
      },
      "outputs": [],
      "source": [
        "class_labels = list(train_augmented.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9vO8GYtQQmo"
      },
      "outputs": [],
      "source": [
        "class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrgJHlUfQ5gi"
      },
      "outputs": [],
      "source": [
        "len(test_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJZDyMu6J0tE"
      },
      "outputs": [],
      "source": [
        "# prompt: find index of 1 in array\n",
        "\n",
        "import numpy as np\n",
        "arr = np.array([0, 1, 0, 1, 0])\n",
        "index_of_ones = np.where(arr == 1)[0]\n",
        "print(index_of_ones)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_Zy6xVAPaOb"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_images, test_labels = next(iter(test_augmented))\n",
        "predictions = model.predict(test_images)\n",
        "i=0\n",
        "for p in predictions:\n",
        "  print(test_labels[i], class_labels[np.argmax(p)])\n",
        "  i+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFdcqfUAQl7T"
      },
      "outputs": [],
      "source": [
        "class_labels[np.argmax(predictions[0])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41l8Nm1qERBi"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqrlwtmj-kde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDNmlXzT6JHT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0kGwiT-tEMy2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "def your_fuction(input):\n",
        "  #your function implementation\n",
        "  return output\n",
        "#define your gradio interface\n",
        "  iface = gr.Interface(fn=your_function,inputs=\"text\",outputs=\"text\")\n",
        "#launch the gradio interface\n",
        "  iface.launch(share=true,debug=False)\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/eye.h5')\n",
        "\n",
        "# Assuming you have a way to get class labels from your model or training data\n",
        "# Replace 'train_augmented.class_indices.keys()' with actual class labels if needed\n",
        "class_labels = ['glaucoma', 'diabetic_retinopathy', 'cataract', 'normal']\n",
        "\n",
        "# Define a function to predict the eye disease\n",
        "def predict_eye_disease(image):\n",
        "    # Preprocess the image\n",
        "    image = np.array(image)  # Convert to numpy array\n",
        "    image = tf.image.resize(image, (256, 256))  # Resize image to (256, 256)\n",
        "    # image = image / 255.0  # Normalize image\n",
        "\n",
        "    # Add batch dimension\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Predict the eye disease\n",
        "    prediction = model.predict(image)\n",
        "\n",
        "    # Get the class label of the prediction\n",
        "    predicted_label = class_labels[np.argmax(prediction[0])]\n",
        "\n",
        "    # Return the predicted label\n",
        "    return predicted_label\n",
        "\n",
        "# Create a Gradio interface\n",
        "image_input = gr.Image(type=\"numpy\")  # Set type to numpy to handle the image correctly\n",
        "label_output = gr.Label(num_top_classes=4)  # Adjust the number of top classes as needed\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=predict_eye_disease,\n",
        "    inputs=image_input,\n",
        "    outputs=label_output,\n",
        "    examples=[\n",
        "        '/kaggle/input/eye-diseases-classification/dataset/cataract/0_left.jpg',\n",
        "        '/kaggle/input/eye-diseases-classification/dataset/diabetic_retinopathy/10003_left.jpeg',\n",
        "        '/kaggle/input/eye-diseases-classification/dataset/glaucoma/1020_left.jpg',\n",
        "        '/kaggle/input/eye-diseases-classification/dataset/normal/1034_left.jpg'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2440665,
          "sourceId": 4130910,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}